{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_icoer_experiments.ipynb\n",
    "\n",
    "**Experimentos com ICOER: Índice de Coerência Informacional (Versão Refinada com MASTER TGU)**\n",
    "\n",
    "Notebook para explorar a métrica ICOER e suas aplicações computacionais, agora integrado ao refinamento MASTER TGU\n",
    "(fator de resistência à coerência ε^{-n}) para conectar com predições orbitais.\n",
    "\n",
    "Objetivos:\n",
    "- Calcular ICOER entre distribuições/estados\n",
    "- Aplicar ativação coerente modulada por ICOER\n",
    "- Treinar rede simples com regularização de coerência\n",
    "- Observar impacto na eficiência informacional\n",
    "- Conectar ICOER com o fator de resistência MASTER TGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Importar módulos TGU\n",
    "from src.icoer_torch import (\n",
    "    ICOER,\n",
    "    coherence_activation,\n",
    "    icoer_regularization_loss,\n",
    "    ResonanceGateLayer\n",
    ")\n",
    "\n",
    "# Importar MASTER TGU\n",
    "from src.tgu_master import calculate_coherence_factor, RS_INFORMATIONAL, N\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"MASTER TGU - Coherence Exponent n = {N}\")\n",
    "print(f\"MASTER TGU - Solar Coherence Radius rs = {RS_INFORMATIONAL:.8f} AU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Teste básico de ICOER entre dois estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estados dummy\n",
    "batch_size, features = 64, 128\n",
    "coherent_ref = torch.randn(batch_size, features) * 0.2 + 1.0\n",
    "noisy_state = coherent_ref + torch.randn_like(coherent_ref) * 1.5\n",
    "\n",
    "icoer_calc = ICOER()\n",
    "\n",
    "icoer_high = icoer_calc(coherent_ref, coherent_ref)\n",
    "icoer_low  = icoer_calc(noisy_state, coherent_ref)\n",
    "\n",
    "print(f\"ICOER (estado coerente vs si mesmo): {icoer_high.item():.4f}\")\n",
    "print(f\"ICOER (estado ruidoso vs referência): {icoer_low.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coherence Activation + MASTER TGU Coherence Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo orbital: usar fator de coerência do MASTER TGU como modulação extra\n",
    "a_mercury = 0.387\n",
    "master_coherence = calculate_coherence_factor(a_mercury)\n",
    "print(f\"MASTER TGU Coherence Factor para Mercúrio (a={a_mercury}): {master_coherence:.6f}\")\n",
    "\n",
    "# Ativação sem coerência\n",
    "x = torch.randn(batch_size, features) * 2.0\n",
    "relu_out = F.relu(x)\n",
    "\n",
    "# Com ICOER + MASTER factor\n",
    "icoer_high = icoer_calc(x, x)\n",
    "coherent_out = coherence_activation(x, icoer_high) * master_coherence\n",
    "\n",
    "print(f\"Média ReLU padrão:          {relu_out.mean().item():.4f}\")\n",
    "print(f\"Média com ICOER + MASTER:   {coherent_out.mean().item():.4f}\")\n",
    "print(f\"Amplificação média:         {(coherent_out.mean() / relu_out.mean()):.3f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento simples com regularização ICOER + MASTER influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCoherentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.icoer = ICOER()\n",
    "        self.res_gate = ResonanceGateLayer(32)\n",
    "\n",
    "    def forward(self, x, master_factor=1.0):\n",
    "        z = F.relu(self.fc1(x))\n",
    "        z_gated, icoer_mid = self.res_gate(z)\n",
    "        out = self.fc2(z_gated) * master_factor\n",
    "        return out, icoer_mid\n",
    "\n",
    "model = SimpleCoherentNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Dados dummy\n",
    "x_clean = torch.randn(256, 64).to(device)\n",
    "x_noisy = x_clean + torch.randn_like(x_clean) * 0.8\n",
    "\n",
    "# MASTER TGU factor (exemplo com Mercúrio)\n",
    "master_factor = calculate_coherence_factor(0.387)\n",
    "\n",
    "losses, icoers = [], []\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    recon, icoer = model(x_noisy, master_factor)\n",
    "    \n",
    "    recon_loss = F.mse_loss(recon, x_clean)\n",
    "    coherence_reg = icoer_regularization_loss(icoer, target=0.85, weight=0.15)\n",
    "    \n",
    "    loss = recon_loss + coherence_reg\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    icoers.append(icoer.item())\n",
    "    \n",
    "    if epoch % 40 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Loss: {loss.item():.4f} | Recon: {recon_loss.item():.4f} | ICOER: {icoer.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualização dos resultados do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(losses, label='Total Loss', color='darkblue')\n",
    "ax1.set_title('Evolução da Perda')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(icoers, label='ICOER médio', color='darkgreen')\n",
    "ax2.axhline(0.85, color='gray', linestyle='--', alpha=0.7, label='Target 0.85')\n",
    "ax2.set_title('Evolução do ICOER durante treinamento')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('ICOER')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusões e próximos passos\n",
    "\n",
    "- O refinamento MASTER TGU (ε^{-n}) pode ser integrado como modulação externa em ativações coerentes, simulando perda de coerência com distância.\n",
    "- ICOER alto + fator MASTER resulta em ativações mais estáveis e eficientes.\n",
    "- Próximos experimentos:\n",
    "  - Integrar com AYA-NODE (04_aya_node_prototype.ipynb)\n",
    "  - Aplicar em tarefas reais (classificação, geração)\n",
    "  - Usar ICOER para medir coerência em simulações de spin orbital (conexão com 02_k_derivation_spin.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
